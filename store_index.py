import os
from dotenv import load_dotenv

# âœ… Load .env file
dotenv_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), ".env")
load_dotenv(dotenv_path)

# âœ… Ensure API keys exist
if not os.getenv("GROQ_API_KEY") or not os.getenv("PINECONE_API_KEY"):
    raise ValueError("âŒ API keys missing. Check your .env file.")

# âœ… Import modules AFTER loading .env
from src.helper import load_pdf_file, split_text, download_hugging_face_embeddings
from pinecone import Pinecone, ServerlessSpec
from langchain_pinecone import PineconeVectorStore

# âœ… Initialize Pinecone connection
api_key = os.getenv("PINECONE_API_KEY")
pc = Pinecone(api_key=api_key)

# âœ… Debugging: Check Pinecone connection
print("ğŸ“ Available Pinecone Indexes:", pc.list_indexes().names())

# âœ… Define Pinecone index
index_name = "test"

# âœ… Check if the index exists before creating it
if index_name not in pc.list_indexes().names():
    print("âœ… Creating new Pinecone index...")
    pc.create_index(
        name=index_name,
        dimension=384,  
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")  
    )
else:
    print(f"âœ… Index '{index_name}' already exists.")

# âœ… Connect to Pinecone index
index = pc.Index(index_name)

# âœ… Get stored vector count
vector_count = index.describe_index_stats()["total_vector_count"]
print(f"ğŸ“Š Pinecone currently stores {vector_count} chunks.")

# âœ… Extract and process text data
print("ğŸ“‚ Loading PDF files from 'data/' directory...")
if not os.path.exists("data"):
    raise FileNotFoundError("âŒ 'data/' directory not found! Please add PDFs.")

extracted_data = load_pdf_file("data")
if not extracted_data:
    raise ValueError("âŒ No PDFs found in 'data/'. Please add files.")

# âœ… Splitting text
text_chunks = split_text(extracted_data)
print("ğŸ“„ First 5 chunks to be indexed:")
for i, chunk in enumerate(text_chunks[:5]):
    print(f"Chunk {i+1}: {chunk.page_content[:300]}...")

# âœ… Indexing only if new data is present
if vector_count < len(text_chunks):
    print("âœ… Indexing new chunks...")
    docsearch = PineconeVectorStore.from_documents(
        documents=text_chunks,
        index_name=index_name,
        embedding=download_hugging_face_embeddings(),
    )
    print(f"âœ… Successfully indexed {len(text_chunks)} chunks!")
